{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ass3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1nPxJzkOFXteWMeeZI0Fa7-waELfYuZMY",
      "authorship_tag": "ABX9TyNcEcnE21Ey7+mF4idp3GD3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annkamsk/ASD-problems/blob/master/Ass3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70T7A0PAoZ5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import pandas as pd \n",
        "from pandas import IntervalDtype\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV7qP8I-pwXf",
        "colab_type": "code",
        "outputId": "e0ac7edd-d244-4732-aaeb-3a040563406c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "TRAIN_PATH = '/content/drive/My Drive/MIM/dl_lab/ass3/train_x.csv'\n",
        "TRAIN_LABEL_PATH = '/content/drive/My Drive/MIM/dl_lab/ass3/train_y.csv'\n",
        "TEST_PATH = '/content/drive/My Drive/MIM/dl_lab/ass3/test_x.csv'\n",
        "TEST_LABEL_PATH = '/content/drive/My Drive/MIM/dl_lab/ass3/test_y.csv'\n",
        "BEST_PATH = '/content/drive/My Drive/MIM/dl_lab/ass3/best.pth'\n",
        "\n",
        "class Config:\n",
        "  def __init__(self, bs=4, epochs=5, output=4, inputs=2, hidden=2, seq_len=5, layers=1, trunc=False):\n",
        "    self.bs = bs\n",
        "    self.epochs = epochs\n",
        "    self.output = output\n",
        "    self.inputs = inputs\n",
        "    self.hidden = hidden\n",
        "    self.seq_len = seq_len\n",
        "    self.layers = layers\n",
        "    self.trunc = trunc\n",
        "\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data, col):\n",
        "        self.data = data\n",
        "        self.label = col\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.data[index], self.label[index]\n",
        "\n",
        "\n",
        "train_csv = pd.read_csv(TRAIN_PATH, header=None).values\n",
        "train_labels_csv = pd.read_csv(TRAIN_LABEL_PATH,header=None,dtype=np.int64).values\n",
        "test_csv = pd.read_csv(TEST_PATH, header=None).values\n",
        "test_labels_csv = pd.read_csv(TEST_LABEL_PATH,header=None,dtype=np.int64).values\n",
        "\n",
        "train = []\n",
        "for row in train_csv:\n",
        "  train.append([[int(v) for v in val.split('-')] for val in row])\n",
        "train = np.array(train)\n",
        "\n",
        "test = []\n",
        "for row in test_csv:\n",
        "  test.append([[int(v) for v in val.split('-')] for val in row])\n",
        "test = np.array(test)\n",
        "\n",
        "train_torch = torch.from_numpy(train)\n",
        "target_torch = torch.from_numpy(train_labels_csv)\n",
        "test_torch = torch.from_numpy(test)\n",
        "test_target_torch = torch.from_numpy(test_labels_csv)\n",
        "\n",
        "train = MyDataset(train_torch, target_torch)\n",
        "train_loader = DataLoader(train, batch_size = Config().bs, shuffle=True)\n",
        "test = MyDataset(test_torch, test_target_torch)\n",
        "test_loader = DataLoader(test, batch_size = Config().bs, shuffle=False)\n",
        "\n",
        "def show_movement(row, label):\n",
        "  xx, yy = np.meshgrid(np.arange(10), np.arange(10), indexing='ij')\n",
        "\n",
        "  def get_mesh(row):\n",
        "    V = []\n",
        "    row = np.array(row)\n",
        "    originX, originY = [], []\n",
        "    for a, b in zip(row, row[1:]):\n",
        "      originX.append(a[0])\n",
        "      originY.append(a[1])\n",
        "      vec = b - a\n",
        "      V.append([vec[0], vec[1]])\n",
        "    return np.array(V), np.array(originX), np.array(originY)\n",
        "\n",
        "  Z, oX, oY = get_mesh(row)\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.scatter(xx, yy)\n",
        "  plt.quiver(oX, oY, Z[:,0], Z[:,1], color=['r','indigo','goldenrod','aquamarine'], angles='xy', scale_units='xy', scale=1)\n",
        "  plt.title(label, color='w')\n",
        "  plt.show()\n",
        "\n",
        "items = iter(train_loader).next()\n",
        "show_movement(items[0][0], items[1][0])\n"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2140nX3oeLzZ",
        "colab_type": "text"
      },
      "source": [
        "## Data analysis\n",
        "3: LD, RG, RD, LG  (to the bottom left?)  \n",
        "1: (to the upper left), RD, RG, LG, LG; LD, LG, LD, LG  \n",
        "0: (to the upper right?), LG, RG, RG, RD; RGx4    \n",
        "2: (to bottom right) RG, LG, RD, LD; \n",
        "RD, RD, LD, RD; \n",
        "RD, LG, RG, RG  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu5jlwN9rvqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7cimDiVns3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "class RNNet(nn.Module):\n",
        "  def __init__(self, input_size, output_size, hidden_dim, bs, layers=1, trunc=False):\n",
        "    super(RNNet, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.output_size = output_size\n",
        "    self.layers = layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.bs = bs\n",
        "    self.trunc = trunc\n",
        "    random.seed()\n",
        "\n",
        "    self.lstm = nn.LSTM(\n",
        "        input_size=input_size, \n",
        "        hidden_size=hidden_dim, \n",
        "        num_layers=layers,\n",
        "        batch_first=True)\n",
        "    self.seq = nn.Linear(hidden_dim, output_size)\n",
        "    # nn.Sequential(\n",
        "    #     nn.Linear(hidden_dim, hidden_dim),\n",
        "    #     nn.ReLU(True),\n",
        "    #     nn.Linear(hidden_dim, hidden_dim),\n",
        "    #     nn.ReLU(True),\n",
        "    #     nn.Linear(hidden_dim, output_size)\n",
        "    # )\n",
        "  \n",
        "  def init_hidden(self):\n",
        "    h = Variable(torch.zeros(self.layers, self.bs, self.hidden_dim).cuda())\n",
        "    c = Variable(torch.zeros(self.layers, self.bs, self.hidden_dim).cuda())\n",
        "    return (h, c)\n",
        "\n",
        "  def pad_input(self, x):\n",
        "    # using variable seq lengts: https://stackoverflow.com/a/49473068/7196167\n",
        "    if self.trunc and random.random() >= 0.5:\n",
        "      x = x[:,:4,:]\n",
        "      seq_lengths = [4] * self.bs\n",
        "    else:\n",
        "      seq_lengths = [5] * self.bs\n",
        "    res = nn.utils.rnn.pack_padded_sequence(x, seq_lengths, batch_first=True)\n",
        "    return res\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.float()    \n",
        "    lstm_input = self.pad_input(x)\n",
        "    # x = (bs, seq_len=5, feature=2)\n",
        "    lstm_out, hidden = self.lstm(lstm_input, self.init_hidden())\n",
        "    lstm_out, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
        "    y = self.seq(lstm_out[:, -1, :])\n",
        "    return y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe9Gy7eGm7tt",
        "colab_type": "text"
      },
      "source": [
        "- input dimension: nr of variables (2)\n",
        "- hidden dimension: size of hidden and cell state at each time step\n",
        "- nr of layers (default 1)\n",
        "- output dimension: nr of classes (4)\n",
        "lstm_layer = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True)\n",
        "\n",
        "https://blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-jj4RWq1Tvi",
        "colab_type": "text"
      },
      "source": [
        "## Train definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPELH3rfdS0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def test(model):\n",
        "  correct, total = 0., 0.\n",
        "  for data, target in test_loader:\n",
        "    data, target = data.cuda(), target.cuda()\n",
        "    out = model(data)\n",
        "    preds = F.log_softmax(out, dim=1).argmax(dim=1)\n",
        "    total += target.size(0)\n",
        "    correct += (preds == target.squeeze()).sum().item()\n",
        "  return correct / total\n",
        "\n",
        "def train_epoch(model, optimizer, criterion, epoch, best):\n",
        "  total, total_correct = 0., 0.\n",
        "  for idx, (data, target) in enumerate(train_loader):\n",
        "    model.train()\n",
        "    data, target = data.cuda(), target.cuda()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = criterion(output, target.squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if idx % 100 == 0:\n",
        "      model.eval()\n",
        "      acc = test(model)\n",
        "      print('Train epoch {}, idx: {}\\t Loss {:.4f}\\t Acc: {:.2f}%'.format(\n",
        "          epoch,\n",
        "          idx,\n",
        "          loss.item(),\n",
        "          acc * 100\n",
        "      ))\n",
        "      if acc > best:\n",
        "        best = acc\n",
        "        torch.save(model.state_dict(), BEST_PATH)\n",
        "\n",
        "def train(conf):\n",
        "  model = RNNet(conf.inputs, conf.output, conf.hidden, conf.bs, conf.layers, conf.trunc)\n",
        "  model.cuda()\n",
        "  lr = 0.0005\n",
        "  optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  best = 0.0\n",
        "  for epoch in range(conf.epochs):\n",
        "    train_epoch(model, optimizer, criterion, epoch, best)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBn1FJdCW6J5",
        "colab_type": "text"
      },
      "source": [
        "## Train on raw data - truncated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TklqNkFXgnel",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "da8e4557-e8d7-4fdc-b505-873011ae4012"
      },
      "source": [
        "train(Config(bs=4, epochs=1, output=4, inputs=2, hidden=256, seq_len=5, layers=1, trunc=True))"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train epoch 0, idx: 0\t Loss 1.3762\t Acc: 27.50%\n",
            "Train epoch 0, idx: 100\t Loss 1.1831\t Acc: 38.30%\n",
            "Train epoch 0, idx: 200\t Loss 1.4453\t Acc: 55.30%\n",
            "Train epoch 0, idx: 300\t Loss 1.3143\t Acc: 53.70%\n",
            "Train epoch 0, idx: 400\t Loss 0.9617\t Acc: 52.50%\n",
            "Train epoch 0, idx: 500\t Loss 0.8231\t Acc: 53.10%\n",
            "Train epoch 0, idx: 600\t Loss 0.7775\t Acc: 53.40%\n",
            "Train epoch 0, idx: 700\t Loss 0.9119\t Acc: 58.10%\n",
            "Train epoch 0, idx: 800\t Loss 0.9072\t Acc: 60.80%\n",
            "Train epoch 0, idx: 900\t Loss 0.6889\t Acc: 61.00%\n",
            "Train epoch 0, idx: 1000\t Loss 0.9005\t Acc: 62.20%\n",
            "Train epoch 0, idx: 1100\t Loss 0.9674\t Acc: 61.10%\n",
            "Train epoch 0, idx: 1200\t Loss 0.4543\t Acc: 57.80%\n",
            "Train epoch 0, idx: 1300\t Loss 1.1945\t Acc: 63.60%\n",
            "Train epoch 0, idx: 1400\t Loss 0.4621\t Acc: 62.10%\n",
            "Train epoch 0, idx: 1500\t Loss 0.4397\t Acc: 63.10%\n",
            "Train epoch 0, idx: 1600\t Loss 1.3084\t Acc: 62.70%\n",
            "Train epoch 0, idx: 1700\t Loss 0.4154\t Acc: 63.40%\n",
            "Train epoch 0, idx: 1800\t Loss 1.0369\t Acc: 61.70%\n",
            "Train epoch 0, idx: 1900\t Loss 1.7852\t Acc: 63.90%\n",
            "Train epoch 0, idx: 2000\t Loss 1.5174\t Acc: 64.30%\n",
            "Train epoch 0, idx: 2100\t Loss 0.6307\t Acc: 63.10%\n",
            "Train epoch 0, idx: 2200\t Loss 0.4050\t Acc: 63.80%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LII30WTtXDZr",
        "colab_type": "text"
      },
      "source": [
        "## Train on raw data - not truncated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A68dt2vUebJQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1ebb3b8e-6ea1-4b0b-c4e6-5eae11fa8625"
      },
      "source": [
        "train(Config(bs=4, epochs=5, output=4, inputs=2, hidden=256, seq_len=5, layers=1, trunc=False))"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train epoch 0, idx: 0\t Loss 1.3792\t Acc: 24.90%\n",
            "Train epoch 0, idx: 100\t Loss 1.0769\t Acc: 45.30%\n",
            "Train epoch 0, idx: 200\t Loss 0.9148\t Acc: 51.40%\n",
            "Train epoch 0, idx: 300\t Loss 1.0761\t Acc: 61.50%\n",
            "Train epoch 0, idx: 400\t Loss 0.9671\t Acc: 58.90%\n",
            "Train epoch 0, idx: 500\t Loss 1.1472\t Acc: 65.20%\n",
            "Train epoch 0, idx: 600\t Loss 1.1468\t Acc: 64.90%\n",
            "Train epoch 0, idx: 700\t Loss 1.2790\t Acc: 66.20%\n",
            "Train epoch 0, idx: 800\t Loss 0.5091\t Acc: 62.20%\n",
            "Train epoch 0, idx: 900\t Loss 1.6837\t Acc: 67.10%\n",
            "Train epoch 0, idx: 1000\t Loss 1.0141\t Acc: 67.00%\n",
            "Train epoch 0, idx: 1100\t Loss 0.7244\t Acc: 63.30%\n",
            "Train epoch 0, idx: 1200\t Loss 0.9620\t Acc: 62.90%\n",
            "Train epoch 0, idx: 1300\t Loss 1.8673\t Acc: 62.00%\n",
            "Train epoch 0, idx: 1400\t Loss 0.9960\t Acc: 63.50%\n",
            "Train epoch 0, idx: 1500\t Loss 1.1523\t Acc: 66.40%\n",
            "Train epoch 0, idx: 1600\t Loss 0.7686\t Acc: 67.40%\n",
            "Train epoch 0, idx: 1700\t Loss 1.5153\t Acc: 67.00%\n",
            "Train epoch 0, idx: 1800\t Loss 0.7608\t Acc: 66.80%\n",
            "Train epoch 0, idx: 1900\t Loss 0.7094\t Acc: 67.60%\n",
            "Train epoch 0, idx: 2000\t Loss 0.8282\t Acc: 66.40%\n",
            "Train epoch 0, idx: 2100\t Loss 0.4171\t Acc: 67.60%\n",
            "Train epoch 0, idx: 2200\t Loss 0.7408\t Acc: 66.50%\n",
            "Train epoch 1, idx: 0\t Loss 0.9522\t Acc: 66.90%\n",
            "Train epoch 1, idx: 100\t Loss 0.9545\t Acc: 67.90%\n",
            "Train epoch 1, idx: 200\t Loss 0.8203\t Acc: 67.40%\n",
            "Train epoch 1, idx: 300\t Loss 0.5521\t Acc: 68.60%\n",
            "Train epoch 1, idx: 400\t Loss 1.7458\t Acc: 68.60%\n",
            "Train epoch 1, idx: 500\t Loss 0.7906\t Acc: 67.90%\n",
            "Train epoch 1, idx: 600\t Loss 0.7555\t Acc: 66.00%\n",
            "Train epoch 1, idx: 700\t Loss 1.0029\t Acc: 66.60%\n",
            "Train epoch 1, idx: 800\t Loss 0.3992\t Acc: 67.10%\n",
            "Train epoch 1, idx: 900\t Loss 2.2659\t Acc: 65.50%\n",
            "Train epoch 1, idx: 1000\t Loss 0.9917\t Acc: 67.40%\n",
            "Train epoch 1, idx: 1100\t Loss 1.3456\t Acc: 67.50%\n",
            "Train epoch 1, idx: 1200\t Loss 0.7915\t Acc: 67.90%\n",
            "Train epoch 1, idx: 1300\t Loss 1.3985\t Acc: 65.50%\n",
            "Train epoch 1, idx: 1400\t Loss 1.7303\t Acc: 62.60%\n",
            "Train epoch 1, idx: 1500\t Loss 0.2925\t Acc: 66.40%\n",
            "Train epoch 1, idx: 1600\t Loss 0.9031\t Acc: 67.00%\n",
            "Train epoch 1, idx: 1700\t Loss 1.1577\t Acc: 68.60%\n",
            "Train epoch 1, idx: 1800\t Loss 0.2725\t Acc: 65.70%\n",
            "Train epoch 1, idx: 1900\t Loss 1.0741\t Acc: 67.70%\n",
            "Train epoch 1, idx: 2000\t Loss 0.7683\t Acc: 67.90%\n",
            "Train epoch 1, idx: 2100\t Loss 0.1874\t Acc: 67.30%\n",
            "Train epoch 1, idx: 2200\t Loss 0.5531\t Acc: 65.40%\n",
            "Train epoch 2, idx: 0\t Loss 0.4234\t Acc: 66.30%\n",
            "Train epoch 2, idx: 100\t Loss 0.4774\t Acc: 67.10%\n",
            "Train epoch 2, idx: 200\t Loss 1.0294\t Acc: 66.80%\n",
            "Train epoch 2, idx: 300\t Loss 0.9563\t Acc: 65.80%\n",
            "Train epoch 2, idx: 400\t Loss 0.8118\t Acc: 67.80%\n",
            "Train epoch 2, idx: 500\t Loss 0.3989\t Acc: 67.80%\n",
            "Train epoch 2, idx: 600\t Loss 1.1784\t Acc: 65.90%\n",
            "Train epoch 2, idx: 700\t Loss 0.7773\t Acc: 66.20%\n",
            "Train epoch 2, idx: 800\t Loss 1.0803\t Acc: 67.70%\n",
            "Train epoch 2, idx: 900\t Loss 0.9235\t Acc: 66.60%\n",
            "Train epoch 2, idx: 1000\t Loss 0.2469\t Acc: 68.60%\n",
            "Train epoch 2, idx: 1100\t Loss 1.1269\t Acc: 67.10%\n",
            "Train epoch 2, idx: 1200\t Loss 0.6761\t Acc: 68.90%\n",
            "Train epoch 2, idx: 1300\t Loss 0.8222\t Acc: 68.40%\n",
            "Train epoch 2, idx: 1400\t Loss 1.0138\t Acc: 67.40%\n",
            "Train epoch 2, idx: 1500\t Loss 0.7959\t Acc: 66.80%\n",
            "Train epoch 2, idx: 1600\t Loss 1.4041\t Acc: 69.00%\n",
            "Train epoch 2, idx: 1700\t Loss 0.9451\t Acc: 66.40%\n",
            "Train epoch 2, idx: 1800\t Loss 1.4176\t Acc: 67.70%\n",
            "Train epoch 2, idx: 1900\t Loss 0.2518\t Acc: 66.70%\n",
            "Train epoch 2, idx: 2000\t Loss 0.9726\t Acc: 68.60%\n",
            "Train epoch 2, idx: 2100\t Loss 0.3975\t Acc: 67.50%\n",
            "Train epoch 2, idx: 2200\t Loss 0.4609\t Acc: 68.10%\n",
            "Train epoch 3, idx: 0\t Loss 0.8447\t Acc: 68.00%\n",
            "Train epoch 3, idx: 100\t Loss 0.5525\t Acc: 67.40%\n",
            "Train epoch 3, idx: 200\t Loss 1.3713\t Acc: 65.70%\n",
            "Train epoch 3, idx: 300\t Loss 1.0502\t Acc: 65.80%\n",
            "Train epoch 3, idx: 400\t Loss 0.3171\t Acc: 67.30%\n",
            "Train epoch 3, idx: 500\t Loss 0.2757\t Acc: 65.90%\n",
            "Train epoch 3, idx: 600\t Loss 0.3447\t Acc: 66.40%\n",
            "Train epoch 3, idx: 700\t Loss 0.4483\t Acc: 66.60%\n",
            "Train epoch 3, idx: 800\t Loss 1.0770\t Acc: 67.10%\n",
            "Train epoch 3, idx: 900\t Loss 0.8041\t Acc: 66.60%\n",
            "Train epoch 3, idx: 1000\t Loss 1.0896\t Acc: 67.50%\n",
            "Train epoch 3, idx: 1100\t Loss 1.0757\t Acc: 65.80%\n",
            "Train epoch 3, idx: 1200\t Loss 0.8022\t Acc: 68.50%\n",
            "Train epoch 3, idx: 1300\t Loss 0.7387\t Acc: 65.80%\n",
            "Train epoch 3, idx: 1400\t Loss 0.5459\t Acc: 66.50%\n",
            "Train epoch 3, idx: 1500\t Loss 0.2964\t Acc: 68.00%\n",
            "Train epoch 3, idx: 1600\t Loss 1.2578\t Acc: 69.60%\n",
            "Train epoch 3, idx: 1700\t Loss 0.9971\t Acc: 66.50%\n",
            "Train epoch 3, idx: 1800\t Loss 0.7573\t Acc: 67.20%\n",
            "Train epoch 3, idx: 1900\t Loss 0.1635\t Acc: 68.70%\n",
            "Train epoch 3, idx: 2000\t Loss 0.5297\t Acc: 67.60%\n",
            "Train epoch 3, idx: 2100\t Loss 0.4256\t Acc: 66.90%\n",
            "Train epoch 3, idx: 2200\t Loss 1.7214\t Acc: 66.90%\n",
            "Train epoch 4, idx: 0\t Loss 1.3100\t Acc: 67.70%\n",
            "Train epoch 4, idx: 100\t Loss 0.8486\t Acc: 67.40%\n",
            "Train epoch 4, idx: 200\t Loss 1.1514\t Acc: 67.70%\n",
            "Train epoch 4, idx: 300\t Loss 0.9677\t Acc: 67.40%\n",
            "Train epoch 4, idx: 400\t Loss 0.3802\t Acc: 68.30%\n",
            "Train epoch 4, idx: 500\t Loss 0.6663\t Acc: 67.70%\n",
            "Train epoch 4, idx: 600\t Loss 0.9937\t Acc: 68.90%\n",
            "Train epoch 4, idx: 700\t Loss 0.4239\t Acc: 65.50%\n",
            "Train epoch 4, idx: 800\t Loss 0.6521\t Acc: 68.30%\n",
            "Train epoch 4, idx: 900\t Loss 0.7852\t Acc: 65.20%\n",
            "Train epoch 4, idx: 1000\t Loss 0.8394\t Acc: 67.10%\n",
            "Train epoch 4, idx: 1100\t Loss 1.2137\t Acc: 68.10%\n",
            "Train epoch 4, idx: 1200\t Loss 0.2893\t Acc: 67.40%\n",
            "Train epoch 4, idx: 1300\t Loss 0.6565\t Acc: 66.60%\n",
            "Train epoch 4, idx: 1400\t Loss 0.3978\t Acc: 67.40%\n",
            "Train epoch 4, idx: 1500\t Loss 0.5737\t Acc: 67.30%\n",
            "Train epoch 4, idx: 1600\t Loss 0.2656\t Acc: 67.90%\n",
            "Train epoch 4, idx: 1700\t Loss 0.5623\t Acc: 67.00%\n",
            "Train epoch 4, idx: 1800\t Loss 0.7933\t Acc: 68.10%\n",
            "Train epoch 4, idx: 1900\t Loss 0.7378\t Acc: 64.80%\n",
            "Train epoch 4, idx: 2000\t Loss 1.4806\t Acc: 67.50%\n",
            "Train epoch 4, idx: 2100\t Loss 0.9054\t Acc: 67.40%\n",
            "Train epoch 4, idx: 2200\t Loss 1.9283\t Acc: 68.90%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xD06-0OXJ5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}